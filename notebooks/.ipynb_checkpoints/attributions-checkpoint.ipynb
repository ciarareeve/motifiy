{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deeplift-attribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained BPNet model...\n",
      "Model loaded.\n",
      "Converting the model to DeepLIFT format...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convert the model to DeepLIFT format\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting the model to DeepLIFT format...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m deeplift_model \u001b[38;5;241m=\u001b[39m \u001b[43mkc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_model_from_saved_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../results/model/bpnet_model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnonlinear_mxts_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNonlinearMxtsMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepLIFT_GenomicsDefault\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel converted to DeepLIFT format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Define the function to compute attributions\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/new_motif/lib/python3.10/site-packages/deeplift/conversion/kerasapi_conversion.py:359\u001b[0m, in \u001b[0;36mconvert_model_from_saved_files\u001b[0;34m(h5_file, json_file, yaml_file, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     model_class_and_config\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(yaml_file))\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     str_data \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(str_data,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    361\u001b[0m         str_data \u001b[38;5;241m=\u001b[39m str_data\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/new_motif/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/opt/anaconda3/envs/new_motif/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deeplift\n",
    "from deeplift.layers import NonlinearMxtsMode\n",
    "from deeplift.util import get_shuffle_seq_ref_function\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "\n",
    "# Load the trained BPNet model\n",
    "print(\"Loading the trained BPNet model...\")\n",
    "try:\n",
    "    model = tf.keras.models.load_model('../results/model/bpnet_model.h5')\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert the model to DeepLIFT format\n",
    "print(\"Converting the model to DeepLIFT format...\")\n",
    "try:\n",
    "    deeplift_model = kc.convert_model_from_saved_files(\n",
    "        '../results/model/bpnet_model.h5',\n",
    "        nonlinear_mxts_mode=NonlinearMxtsMode.DeepLIFT_GenomicsDefault\n",
    "    )\n",
    "    print(\"Model converted to DeepLIFT format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error converting model to DeepLIFT format: {e}\")\n",
    "    raise\n",
    "\n",
    "# Define the function to compute attributions\n",
    "find_scores_layer_idx = -1\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "    find_scores_layer_idx=find_scores_layer_idx,\n",
    "    pre_activation_target_layer_idx=find_scores_layer_idx\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "print(\"Loading validation data...\")\n",
    "input_data = np.load('../data/processed/X_val.npy')\n",
    "\n",
    "# Compute attributions\n",
    "print(\"Computing attributions...\")\n",
    "try:\n",
    "    attributions = np.array(deeplift_contribs_func(\n",
    "        task_idx=0,  # Assuming single-task model\n",
    "        input_data_list=[input_data],\n",
    "        input_references_list=[np.zeros_like(input_data)],\n",
    "        batch_size=10,\n",
    "        progress_update=1\n",
    "    ))\n",
    "    print(\"Attributions computed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error computing attributions: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save attributions\n",
    "print(\"Saving attributions...\")\n",
    "np.save('../results/attributions/attributions.npy', attributions)\n",
    "print(\"Attributions saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064971be-cc3c-4e24-a23e-5ab4ab31fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56072\n",
      "-rw-r--r--  1 ciarareeve  staff  14351456 Jun  7 19:42 bpnet_model.h5\n",
      "-rw-r--r--  1 ciarareeve  staff  14348930 Jun  7 19:01 bpnet_model.keras\n",
      "-rw-r--r--  1 ciarareeve  staff      1102 Jun  7 19:29 training_history.npy\n"
     ]
    }
   ],
   "source": [
    "ls -l ../results/model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4dbe372-3d61-4c33-96e0-cf565ce6dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model('../results/model/bpnet_model.keras')\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6915c8c-0750-40ea-8dee-133e01ad0edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the existing model\n",
    "model = tf.keras.models.load_model('../results/model/bpnet_model.keras')\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('../results/model/bpnet_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7addb2-efb8-42b1-8690-ef10247d434c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
